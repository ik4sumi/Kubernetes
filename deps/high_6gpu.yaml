apiVersion: apps/v1
kind: Deployment
metadata:
  name: high-6gpu
  labels:
    k8s-app: high-6gpu
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: high-6gpu
  template:
    metadata: 
      labels:
        k8s-app: high-6gpu
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-A10	
                - NVIDIA-TITAN-RTX
                - NVIDIA-GeForce-RTX-3090
                - NVIDIA-RTX-A5000
                - Quadro-RTX-6000
      containers:
      - name: high-6gpu
        image: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel
        command: ["sh", "-c", "apt update && \
          apt install -y curl && \
          curl -fsSL https://raw.githubusercontent.com/miracleyoo/one-key-linux-setup/master/one-key-setup-for-pytorch-docker.sh -o one-key-setup-for-pytorch-docker.sh && \
          bash one-key-setup-for-pytorch-docker.sh && \
          rm one-key-setup-for-pytorch-docker.sh && \
          sleep infinity"]
        resources:
          limits:
            memory: 32Gi
            cpu: 16
            nvidia.com/gpu: 6
            ephemeral-storage: 100Gi
          requests:
            memory: 32Gi
            cpu: 16
            nvidia.com/gpu: 6
            ephemeral-storage: 100Gi        
        volumeMounts:
        - mountPath: /tsukimi
          name: tsukimi
        - mountPath: /hataraku
          name: hataraku
        - mountPath: /dev/shm
          name: cache-volume
      volumes:
        - name: tsukimi
          persistentVolumeClaim:
            claimName: tsukimi
        - name: hataraku
          persistentVolumeClaim:
            claimName: hataraku
        - emptyDir:
            medium: Memory
            sizeLimit: 1Gi
          name: cache-volume